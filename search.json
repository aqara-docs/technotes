[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Technotes",
    "section": "",
    "text": "기술 문서 (CS팀)",
    "crumbs": [
      "기술 문서 (CS팀)"
    ]
  },
  {
    "objectID": "naver_aqaracafe.html",
    "href": "naver_aqaracafe.html",
    "title": "9  네이버 아카라 카페 웹크롤링",
    "section": "",
    "text": "9.1 환경 변수 설정 및 MySQL. 연결",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>네이버 아카라 카페 웹크롤링</span>"
    ]
  },
  {
    "objectID": "naver_aqaracafe.html#환경-변수-설정-및-mysql.-연결",
    "href": "naver_aqaracafe.html#환경-변수-설정-및-mysql.-연결",
    "title": "9  네이버 아카라 카페 웹크롤링",
    "section": "",
    "text": "from dotenv import load_dotenv\nload_dotenv()\n\ndb_config = {\n    'user': os.getenv('SQL_USER'),\n    'password': os.getenv('SQL_PASSWORD'),\n    'host': os.getenv('SQL_HOST'),\n    'database': os.getenv('SQL_DATABASE'),\n    'charset': 'utf8mb4',\n    'collation': 'utf8mb4_general_ci'\n}\n\ndotenv 라이브러리를 사용해 .env 파일에서 MySQL 및 네이버 카페 로그인 관련 환경 변수를 불러온다.\n이를 통해 MySQL에 연결할 때 필요한 정보를 제공한다.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>네이버 아카라 카페 웹크롤링</span>"
    ]
  },
  {
    "objectID": "naver_aqaracafe.html#네이버-카페-크롤링-클래스-정의",
    "href": "naver_aqaracafe.html#네이버-카페-크롤링-클래스-정의",
    "title": "9  네이버 아카라 카페 웹크롤링",
    "section": "9.2 네이버 카페 크롤링 클래스 정의",
    "text": "9.2 네이버 카페 크롤링 클래스 정의\nclass NaverCafeCrawler:\n    def __init__(self, driver_path, url, id, pw, baseurl, clubid, userDisplay, boardType, db_config):\n        self.total_list = ['registered_date', 'devices', 'title', 'question', 'answers']\n        self.driver_path = driver_path\n        self.url = url\n        self.id = id\n        self.pw = pw\n        self.baseurl = baseurl\n        self.clubid = clubid\n        self.userDisplay = userDisplay\n        self.boardType = boardType\n        self.db_config = db_config\n\nNaverCafeCrawler 클래스는 크롤링의 주요 기능을 수행한다.\n클래스는 로그인 정보, 크롤링할 URL, MySQL 연결 정보 등을 초기화한다.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>네이버 아카라 카페 웹크롤링</span>"
    ]
  },
  {
    "objectID": "naver_aqaracafe.html#로그인-함수",
    "href": "naver_aqaracafe.html#로그인-함수",
    "title": "9  네이버 아카라 카페 웹크롤링",
    "section": "9.3 로그인 함수",
    "text": "9.3 로그인 함수\ndef login(self, browser):\n    browser.get(self.url)\n    browser.implicitly_wait(2)\n    browser.execute_script(f\"document.getElementsByName('id')[0].value='{self.id}'\")\n    browser.execute_script(f\"document.getElementsByName('pw')[0].value='{self.pw}'\")\n    browser.find_element(By.XPATH, '//*[@id=\"log.login\"]').click()\n    time.sleep(1)\n\n네이버 카페에 자동으로 로그인하는 기능이다.\nSelenium을 사용해 ID와 비밀번호를 입력하고 로그인 버튼을 클릭한다.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>네이버 아카라 카페 웹크롤링</span>"
    ]
  },
  {
    "objectID": "naver_aqaracafe.html#페이지-크롤링-함수",
    "href": "naver_aqaracafe.html#페이지-크롤링-함수",
    "title": "9  네이버 아카라 카페 웹크롤링",
    "section": "9.4 페이지 크롤링 함수",
    "text": "9.4 페이지 크롤링 함수\ndef crawl_page(self, browser, page_num):\n    browser.get(f\"{self.baseurl}ArticleList.nhn?search.clubid={self.clubid}&userDisplay={self.userDisplay}&search.boardType={self.boardType}&search.page={page_num}\")\n    browser.switch_to.frame('cafe_main')\n    soup = bs(browser.page_source, 'html.parser')\n    datas = soup.find_all(class_='td_article')\n    ...\n\n지정된 페이지 번호의 게시글 목록을 크롤링한다.\nSelenium을 사용해 카페 게시판의 특정 페이지로 이동하고, BeautifulSoup을 사용해 게시글의 제목, 카테고리, 링크 등을 파싱한다.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>네이버 아카라 카페 웹크롤링</span>"
    ]
  },
  {
    "objectID": "naver_aqaracafe.html#section",
    "href": "naver_aqaracafe.html#section",
    "title": "9  네이버 아카라 카페 웹크롤링",
    "section": "9.5 ",
    "text": "9.5 \n게시글 상세 내용 크롤링\ndef get_content(self, browser, link):\n    browser.get(link)\n    time.sleep(1)\n    browser.switch_to.frame('cafe_main')\n    soup = bs(browser.page_source, 'html.parser')\n    content_text = soup.find(\"div\", {\"class\": \"article_viewer\"}).get_text().strip() if content else \"\"\n    ...\n\n각 게시글의 링크로 이동하여 상세 내용을 크롤링한다.\n게시글의 본문 내용과 등록 날짜, 댓글(답변)을 추출한다.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>네이버 아카라 카페 웹크롤링</span>"
    ]
  },
  {
    "objectID": "naver_aqaracafe.html#mysql-저장-함수",
    "href": "naver_aqaracafe.html#mysql-저장-함수",
    "title": "9  네이버 아카라 카페 웹크롤링",
    "section": "9.6 MySQL 저장 함수",
    "text": "9.6 MySQL 저장 함수\ndef save_to_mysql(self, df):\n    conn = mysql.connector.connect(**self.db_config)\n    cursor = conn.cursor()\n\n    for _, row in df.iterrows():\n        check_sql = \"SELECT COUNT(*) FROM aqara_cafe WHERE registered_date = %s AND title = %s\"\n        cursor.execute(check_sql, (row['registered_date'], row['title']))\n        result = cursor.fetchone()\n\n        if result[0] == 0:\n            insert_sql = \"INSERT INTO aqara_cafe (registered_date, devices, title, question, answers) VALUES (%s, %s, %s, %s, %s)\"\n            cursor.execute(insert_sql, tuple(row))\n    \n    conn.commit()\n    cursor.close()\n    conn.close()\n\n크롤링한 데이터를 DataFrame으로 받아 MySQL 데이터베이스에 저장하는 기능이다.\n중복된 데이터를 방지하기 위해 registered_date와 title을 기준으로 이미 데이터가 존재하는지 확인한 후, 존재하지 않으면 데이터를 삽입한다.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>네이버 아카라 카페 웹크롤링</span>"
    ]
  },
  {
    "objectID": "naver_aqaracafe.html#크롤러-실행",
    "href": "naver_aqaracafe.html#크롤러-실행",
    "title": "9  네이버 아카라 카페 웹크롤링",
    "section": "9.7 크롤러 실행",
    "text": "9.7 크롤러 실행\ncrawler = NaverCafeCrawler(driver_path, url, id, pw, baseurl, clubid, userDisplay, boardType, db_config)\ncrawler.run(max_pages=params_pages)\n\n설정된 매개변수로 크롤링을 실행한다.\n최대 페이지 수(max_pages) 만큼 페이지를 순차적으로 크롤링하고, 데이터를 CSV로 저장한 후 MySQL로 전송한다.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>네이버 아카라 카페 웹크롤링</span>"
    ]
  },
  {
    "objectID": "channeltalk.html",
    "href": "channeltalk.html",
    "title": "8  채널톡 API 연동",
    "section": "",
    "text": "8.1 API 연동",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>채널톡 API 연동</span>"
    ]
  },
  {
    "objectID": "channeltalk.html#api-연동",
    "href": "channeltalk.html#api-연동",
    "title": "8  채널톡 API 연동",
    "section": "",
    "text": "8.1.1 API 인증키 만들기\n\n\n\n8.1.2 Access Key와 Access Secret을 이용한 API 연동\n[참고] 새 API의 경우 access token 방식으로 바뀜. 여전히 아래 방식 사용 가능\nimport requests\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\naccess_key = \"xxxxxxx\"\naccess_secret = \"xxxxxxx\"\n\n# 어제와 오늘의 날짜 구하기\nyesterday = datetime.now() - timedelta(days=1)\ntoday = datetime.now()\n\n# API 엔드포인트 및 인증 정보\nurl = \"https://api.channel.io/open/v5/user-chats\"\nheaders = {\n    \"accept\": \"application/json\",\n    \"x-access-key\": f\"{access_key}\",\n    \"x-access-secret\": f\"{access_secret}\"\n}\nparams = {\n    \"state\": \"opened\",\n    \"sortOrder\": \"desc\",\n    \"limit\": 100,\n    \"from\": int(yesterday.timestamp() * 1000),  # 어제 자정부터\n    \"to\": int(today.timestamp() * 1000)  # 현재까지\n}\n\n# API 요청 보내기\nresponse = requests.get(url, headers=headers, params=params)\n\n# 응답 확인\nif response.status_code == 200:\n    chats = response.json().get(\"messages\", [])\n    #print(chats)\n    df = pd.DataFrame(chats)\n    df = df[['personType','plainText', 'updatedAt', 'createdAt']].rename(columns={'plainText': 'text'})\n    df = df[df['text'].str.strip() != '']\n    # updatedAt과 createdAt의 timestamp 값을 datetime 형식으로 변환\n    df['updatedAt'] = pd.to_datetime(df['updatedAt'], unit='ms') + pd.Timedelta(hours=9)\n    df['createdAt'] = pd.to_datetime(df['createdAt'], unit='ms') + pd.Timedelta(hours=9)\n    df_sorted = df.loc[df['personType']==\"user\", ['updatedAt', 'text','personType']].sort_values(by='updatedAt', ascending=False)\n    df_sorted.loc[:,['updatedAt','text']].dropna().head(10)\nelse:\n    print(\"API 요청에 실패하였습니다.\")",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>채널톡 API 연동</span>"
    ]
  },
  {
    "objectID": "channeltalk.html#주요-코드-분석",
    "href": "channeltalk.html#주요-코드-분석",
    "title": "8  채널톡 API 연동",
    "section": "8.2 주요 코드 분석",
    "text": "8.2 주요 코드 분석\n\n8.2.1 환경 변수 로드 및 인증 정보 설정\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\n\nchanneltalk_access_key = os.getenv('CHANNELTALK_ACCESS_KEY')\nchanneltalk_access_secret = os.getenv('CHANNELTALK_ACCESS_SECRET')* \n\ndotenv를 사용해 .env 파일에서 채널톡 API 인증 정보(CHANNELTALK_ACCESS_KEY, CHANNELTALK_ACCESS_SECRET)를 로드한다. 이를 통해 API 요청에 필요한 인증 정보를 설정한다.\n\n\n\n8.2.2 날짜 설정\nyesterday = datetime.now() - timedelta(days=1)\ntoday = datetime.now()\n\nyesterday는 어제의 날짜, today는 오늘의 날짜를 나타낸다. 채팅 데이터를 검색할 기간을 설정하는 데 사용된다.\n\n\n\n8.2.3 API 요청 파라미터 설정\nparams = {\n    \"state\": params_state,\n    \"sortOrder\": params_sort,\n    \"limit\": params_limit,\n    \"from\": int(yesterday.timestamp() * 1000),  # 어제 자정부터\n    \"to\": int(today.timestamp() * 1000)  # 현재까지\n}\nAPI 요청에 사용할 파라미터를 설정합니다.\n\nstate: 고객 지원 상태 (opened 또는 closed)\nsortOrder: 정렬 순서 (desc 또는 asc)\nlimit: 요청할 데이터의 수 (최소 20, 최대 500)\nfrom/to: 검색할 기간의 시작과 끝을 Unix timestamp 형식으로 변환한 값입니다.\n\n\n\n8.2.4 \nAPI 요청 및 응답 처리\nresponse = requests.get(url, headers=headers, params=params)\nif response.status_code == 200:\n    chats = response.json().get(\"messages\", [])\n    df = pd.DataFrame(chats)\nrequests.get()을 사용하여 설정된 URL과 파라미터로 API 요청을 보내고, 성공하면 응답 데이터를 JSON 형식으로 받아서 처리한다.\n\n응답 데이터에서 messages 키에 해당하는 데이터를 추출하여 pandas DataFrame으로 변환한다.\n\n\n\n8.2.5 데이터 정제 및 변환\ndf = df[['plainText', 'updatedAt', 'createdAt']].rename(columns={'plainText': 'text'})\ndf['updatedAt'] = pd.to_datetime(df['updatedAt'], unit='ms') + pd.Timedelta(hours=9)\ndf['createdAt'] = pd.to_datetime(df['createdAt'], unit='ms') + pd.Timedelta(hours=9)\ndf_sorted = df.loc[:, ['updatedAt', 'text']].sort_values(by='updatedAt', ascending=sort_status)\n\nAPI에서 받은 데이터를 plainText, updatedAt, createdAt 컬럼만 추출하고, 이를 적절하게 이름 변경(text)하고 정렬한다.\n타임스탬프 값을 datetime 형식으로 변환한 후, 시간대를 고려해 9시간을 더한다. (한국 시간 기준)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>채널톡 API 연동</span>"
    ]
  },
  {
    "objectID": "homeassistant.html",
    "href": "homeassistant.html",
    "title": "1  허브 M3와 매터 - Home Assistant",
    "section": "",
    "text": "1.1 Matter에 관한 기본 상식\nMatter는 스마트 홈 기기들을 서로 호환되게 연결하기 위해 개발된 표준 프로토콜입니다. 이 표준은 다양한 제조사의 스마트 홈 제품들이 원활하게 통신하고 제어될 수 있도록 하기 위해 설계되었습니다. Matter는 Zigbee Alliance(현재는 Connectivity Standards Alliance, CSA로 명칭 변경)가 주도하며, 구글, 애플, 아마존, 삼성 등 주요 기술 기업들이 참여하고 있습니다. 아래는 Matter와 관련된 주요 개념들에 대한 설명입니다.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>허브 M3와 매터 - Home Assistant</span>"
    ]
  },
  {
    "objectID": "homeassistant.html#matter에-관한-기본-상식",
    "href": "homeassistant.html#matter에-관한-기본-상식",
    "title": "1  허브 M3와 매터 - Home Assistant",
    "section": "",
    "text": "1.1.1 Matter Controller (or Hub)\nMatter Controller는 Matter 생태계 내에서 여러 장치들을 연결하고 관리하는 중심 역할을 하는 장치입니다. 주로 스마트폰, 스마트 스피커, 스마트 디스플레이 등이 이 역할을 합니다. Matter Controller는 다음과 같은 기능을 수행합니다:\n\n장치 등록 및 설정: 새로운 Matter 장치를 네트워크에 추가하고 초기 설정을 관리합니다.\n장치 관리: 연결된 모든 Matter 장치들을 모니터링하고 제어합니다.\n자동화 및 스케줄링: 다양한 자동화 시나리오와 스케줄을 설정하여 장치들이 특정 조건에서 동작하도록 합니다.\n보안: 네트워크의 보안을 유지하고 장치들 간의 안전한 통신을 보장합니다.\n\n\n\n1.1.2 Matter Bridge\nMatter Bridge는 Matter 네트워크와 다른 프로토콜을 사용하는 장치들 사이의 다리 역할을 합니다. 예를 들어, Zigbee나 Z-Wave 장치를 Matter 네트워크에 통합할 때 사용됩니다. Matter Bridge는 다음과 같은 기능을 수행합니다:\n\n프로토콜 변환: 서로 다른 프로토콜 간의 통신을 가능하게 하여, 비호환 장치들도 Matter 네트워크에서 제어될 수 있도록 합니다.\n통합 관리: 다양한 프로토콜을 사용하는 장치들을 하나의 플랫폼에서 관리할 수 있게 합니다.\n확장성: 기존의 스마트 홈 장치들을 폐기하지 않고 Matter 네트워크에 통합하여 사용자가 더 많은 장치를 활용할 수 있도록 합니다.\n\n\n\n1.1.3 Thread\nThread는 저전력, 저비용, 메시 네트워크 프로토콜로, 스마트 홈 및 IoT 기기들 간의 안정적이고 확장 가능한 통신을 위해 설계되었습니다. Thread는 Matter의 주요 네트워크 기술 중 하나로, 다음과 같은 특징을 가집니다:\n\n메시 네트워크: 모든 장치들이 서로 연결되어 데이터를 전달하며, 네트워크 내의 장치 하나가 고장나더라도 다른 경로를 통해 통신을 지속할 수 있습니다.\n저전력: 배터리로 구동되는 장치들도 효율적으로 통신할 수 있도록 저전력 설계가 되어 있습니다.\n보안: IP 기반 프로토콜을 사용하여 높은 수준의 보안을 제공하며, 네트워크에 연결된 모든 장치 간의 암호화된 통신을 지원합니다.\n확장성: 여러 장치들이 간편하게 네트워크에 추가될 수 있어, 대규모 설치에도 적합합니다.\n\n이러한 개념들을 바탕으로, Matter는 스마트 홈 환경에서의 사용자 경험을 개선하고, 제조사와 사용자 모두에게 더 나은 호환성과 편의성을 제공합니다.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>허브 M3와 매터 - Home Assistant</span>"
    ]
  },
  {
    "objectID": "homeassistant.html#허브-m3",
    "href": "homeassistant.html#허브-m3",
    "title": "1  허브 M3와 매터 - Home Assistant",
    "section": "1.2 허브 M3",
    "text": "1.2 허브 M3\n\nAqara 스마트 허브 M3는 Aqara의 첫 번째 Thread 지원 Border Router로, Thread, Zigbee 3.0 및 Bluetooth 장치를 모두 지원합니다.\n새롭게 업그레이드된 Cross-LAN 및 Cross-HUB 기능을 통해 로컬 자동화와 Matter를 지원하는 강력한 스마트 홈 허브입니다.\nARM 1Ghz 듀얼 코어 A7 아키텍처를 사용하여 다양한 데이터 처리와 자동화 제어에 최적화되어 있습니다.\n2.4GHz와 5GHz 듀얼 밴드 Wi-Fi와 RJ45 포트를 통한 유선 네트워크 연결 및 PoE 전원 공급을 지원합니다. 어댑터를 통한 전원 공급뿐 아니라, USB C 인터페이스의 데이터 통신 기능을 통해 다른 주변 장치와 연결하여 사용할 수 있습니다.\n고출력 적외선 송신기가 전면에 6개, 측면에 4개 탑재되어 넓은 공간에서도 적외선 장치를 안정적으로 제어할 수 있습니다.\n여러 대의 스마트 허브 M3를 동일 네트워크에 구성하면 넓은 영역에서 안정적인 로컬 네트워크를 구현할 수 있습니다.\n허브 대체 기능 덕분에 허브 하나에 문제가 발생해도 다른 허브가 역할을 대신하여 네트워크를 안정적으로 유지할 수 있습니다.\n8GB eMMC 스토리지를 내장하여 클라우드 의존도를 낮추고 사용자 데이터를 보호할 수 있습니다.\n스마트 싱스, 애플 홈킷, 구글홈과 Matter 표준 프로토콜을 지원하는 모든 IoT 플랫폼과 호환됩니다.\nM3가 Matter Controller로 사용될 때 지원 가능한 3rd party 매터기기: 타사 매터지원 장치 중 열림감지 센서, 재실 센서, 조도 센서, 조명스위치, 스마트 플러그, 서모스탯, 매터 브릿지만 연결 가능",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>허브 M3와 매터 - Home Assistant</span>"
    ]
  },
  {
    "objectID": "homeassistant.html#home-assistant-연동---허브-m3를-matter-bridge-연동",
    "href": "homeassistant.html#home-assistant-연동---허브-m3를-matter-bridge-연동",
    "title": "1  허브 M3와 매터 - Home Assistant",
    "section": "1.3 Home Assistant 연동 - 허브 M3를 Matter Bridge 연동",
    "text": "1.3 Home Assistant 연동 - 허브 M3를 Matter Bridge 연동\n\n1.3.1 Home Assistant 환경 구축\n\n2024년 7월 1일 현재 Matter를 문제없이 사용하기 위해서는 Home Assistant를 Supervised 모드로 설치해야 합니다.\n본 실험은 Raspberry Pi 4 (8G)에 Home Assistant Supervised를 설치하여 진행했습니다.\nRaspberry Pi Imager(https://www.raspberrypi.com/software/)을 다운로드하신 후 Raspberry Pi 모델을 지정하고 Home Assistant 선택하면 SD카드에 Home Assistant Supervised가 설치됩니다.\nChoose OS &gt;&gt; Other specific-purpose OS &gt;&gt; Home assistants and home automation &gt;&gt; Home Assistant\nHome Assistant 모바일 버전(안드로이드/iOS) 설치 추천 - Home Assistant IP와 로그인 정보만 입력하면 PC버전과 동기화 됩니다. 매터기기 등록시 QR코드 스캔에 용이합니다.\n\n\n\n1.3.2 허브 M3를 Home Assistant에 매터기기로 등록하기\n\nHome Assistant 메인 메뉴에서 “설정”을 선택합니다.\n\n\n\n\n\n\n\n“기기 및 서비스” 를 선택합니다.\n\n\n\n\n\n\n\n“통합구성요소 추가하기”를 선택합니다.\n\n\n\n\n\n\n\n“Matter 기기 추가”를 선택합니다.\n\n\n\n\n\n\n\n“아니오, 새 제품입니다” 선택하기\n\n\n\n\n\n\n\n아카라홈앱에서 허브 M3의 Matter 페어링 코드를 생성합니다.\n\n\n\n\n\n\n\n위에서 생성된 코드를 Home Assistant의 “Matter QR 코드 스캔”를 통해서 설정합니다.\n\n\n\n\n\n\n\nHome Assistant 대시 보드 구성 후 “둘러보기”에서 확인합니다. 허브 M3에 연결된 스마트 도어락 K100도 Home Assistant에 자동 등록됩니다. Home Assistant에서 도어락 K100 잠금해제 가능합니다.\n\n(참고) Home Assistant에 애플홈킷 지원 G2H/G2H Pro, G3,카메라 E1를 등록하기 위해서 “통합구성요소 추가하기”에서 Apple를 검색하신 후 “HomeKit 기기”로 등록하시면 됩니다.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>허브 M3와 매터 - Home Assistant</span>"
    ]
  },
  {
    "objectID": "homeassistant.html#자동화-예시",
    "href": "homeassistant.html#자동화-예시",
    "title": "1  허브 M3와 매터 - Home Assistant",
    "section": "1.4 자동화 예시",
    "text": "1.4 자동화 예시\n\n1.4.1 시나리오\n카메라가 움직임을 감지하면 스마트 도어락 K100 잠금 해제하기\n\n\n1.4.2 자동화 설정 방법\n\nHome Assistant의 설정 메뉴에서 “자동화 및 장면” 선택하기\n\n\n\n\n\n\n\n자동화 설정하기\n\n조건: G2H 카메라가 움직을 감지했을 때\n수행: 스마트 도어락 K100 잠금해제\n\n\n\n\n\n\n\n\n\n\n\n\n\n자동화 수행 관련 로그 정보",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>허브 M3와 매터 - Home Assistant</span>"
    ]
  },
  {
    "objectID": "googlesheets.html",
    "href": "googlesheets.html",
    "title": "3  고객 서비스 업무 관련 구글 시트 연동",
    "section": "",
    "text": "3.1 목적",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>고객 서비스 업무 관련 구글 시트 연동</span>"
    ]
  },
  {
    "objectID": "googlesheets.html#목적",
    "href": "googlesheets.html#목적",
    "title": "3  고객 서비스 업무 관련 구글 시트 연동",
    "section": "",
    "text": "본 문서는 고객 서비스 업무 관련 구글 시트 연동 방법을 기술한 문서입니다.\n구글 시트 문서는 다음과 같다.\n\n수거 신청 대장\n토탈설치_피엘이엔지_배정_2024하반기\n맞춤커튼_엘엠엑스텍_배정_2024하반기\n설치 업체 배정_하반기 (도어락)\nK100 불량 및 문의 접수표_진행중",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>고객 서비스 업무 관련 구글 시트 연동</span>"
    ]
  },
  {
    "objectID": "googlesheets.html#준비-사항",
    "href": "googlesheets.html#준비-사항",
    "title": "3  고객 서비스 업무 관련 구글 시트 연동",
    "section": "3.2 준비 사항",
    "text": "3.2 준비 사항\n\n참고 사이트: https://develop-davi-kr.tistory.com/entry/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EA%B5%AC%EA%B8%80-%EC%8A%A4%ED%94%84%EB%A0%88%EB%93%9C%EC%8B%9C%ED%8A%B8-%EC%97%B0%EB%8F%99-%EB%B0%8F-%EC%9E%90%EB%8F%99%ED%99%94-%EB%B0%A9%EB%B2%95#google_vignette\n\n\n\n구글 클라우드 서비스 가입 및 서비스 계정 생성 (https://console.cloud.google.com/apis/dashboard)\n\n사용자 인증 정보 &gt;&gt; 프로젝트 만들기\n사장자 인증 정보 만들기 &gt;&gt; 서비스 계정 생성\n서비스 계정의 이메일 정보 클릭 &gt;&gt; 키 생성\n비공개 키를 컴퓨터에 저장(json파일)\n서비스 계정에 생성된 이메일을 구글시트에서 공유 대상으로 지정\n\n구글 시트 API 연동\n\nAPI 및 서비스 &gt;&gt; 라이브러리 클릭 &gt;&gt; Google Sheet 검색 &gt;&gt; Google Sheets API 클릭 &gt;&gt; API 사용 클릭",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>고객 서비스 업무 관련 구글 시트 연동</span>"
    ]
  },
  {
    "objectID": "googlesheets.html#코드-분석",
    "href": "googlesheets.html#코드-분석",
    "title": "3  고객 서비스 업무 관련 구글 시트 연동",
    "section": "3.3 코드 분석",
    "text": "3.3 코드 분석\n\n3.3.1 공통 주요 정보\n\n3.3.1.1 .env 파일에서 환경 변수 로드\n#from dotenv import load_dotenv\n#import os\n#load_dotenv()\n\n\n3.3.1.2 Google Sheets API 인증 및 데이터 로드\n\n구글 시트 스프레드시트 ID: “d/”와 “/edit”사이의 문자\n\n예제&gt; https://docs.google.com/spreadsheets/d/xxxxxxxxxxxxxxxxxx/edit?gid=xxxxx#gid=xxxxxxxx\n\n\n#from google.oauth2.service_account import Credentials\n#import gspread\n# Path to your service account JSON file\n#SERVICE_ACCOUNT_FILE = os.getenv('SERVICE_ACCOUNT_FILE')\n\n# Load credentials from the JSON file\n#creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=[os.getenv('SCOPES')])\n\n# Connect to Google Sheets\n#gc = gspread.authorize(creds)\n\n# Google Sheet ID and Worksheet name\n#SERVICE_SPREADSHEET_ID = os.getenv('SERVICE_SPREADSHEET_ID')\n#SERVICE_WORKSHEET_NAME = os.getenv('SERVICE_WORKSHEET_NAME')  # Replace with your worksheet name\n\nGoogle Sheets API 인증: Google Sheets API를 사용하기 위해 JSON 자격 증명 파일을 통해 인증을 수행합니다.\ngspread 라이브러리: Google Sheets의 데이터에 접근하기 위한 Python 라이브러리로, authorize() 메서드를 사용해 Google Sheets에 접근합니다.\n\n\n\n\n3.3.2 수거 신청 대장\n\n3.3.2.1 구글 시트 데이터 로딩 및 정리\n#def load_sheet_data():\n#    worksheet = gc.open_by_key(SERVICE_SPREADSHEET_ID).worksheet(SERVICE_WORKSHEET_NAME)\n#    all_values = worksheet.get_all_values()\n#    headers = all_values[2]  # 3번째 줄을 헤더로 사용\n#    data = all_values[3:]    # 데이터는 4번째 줄부터 시작\n#    df = pd.DataFrame(data, columns=headers)\n#    df.replace('', np.nan, inplace=True)\n#    df.dropna(subset=['고객명'], inplace=True)\n#    df.columns = make_unique_columns(list(df.columns))\n#    return df\n\n\n목적: Google Sheets에서 데이터를 불러와 Pandas DataFrame으로 변환합니다.\n주요 동작:\n• 첫 두 줄을 건너뛰고, 3번째 줄을 헤더로 사용하며 4번째 줄부터 데이터를 불러옵니다.\n• 빈 문자열을 NaN으로 대체하고, ‘고객명’ 열이 비어있는 행은 제거합니다.\n• make_unique_columns(): 중복된 열 이름이 있을 경우, 이를 고유하게 변경합니다.sk\n\n\n\n3.3.2.2 날짜 파싱 및 형식화\n#for idx, row in df.iterrows():\n#    date_str = row['작성일']\n#    if pd.isna(date_str):\n#        continue\n#    try:\n#        if re.match(r'^\\d{4}\\.\\d{1,2}\\.\\d{1,2}$', date_str):\n#            df.at[idx, 'registered_date'] = pd.to_datetime(date_str, format='%Y.%m.%d')\n# 추가적인 정규 표현식 패턴들\n#    except Exception as e:\n#        df.at[idx, 'registered_date'] = None\n\n목적: 다양한 날짜 형식을 표준화된 날짜 형식으로 변환합니다.\n• 정규 표현식 매칭: 다양한 날짜 형식을 re.match()로 탐지한 후, 이를 pd.to_datetime()을 사용해 변환합니다.\n• 오류 처리: 만약 변환에 실패하거나 형식이 일치하지 않으면 날짜를 None으로 설정합니다.\n\n\n\n\n3.3.3 토탈 설치 서비스\n\n3.3.3.1 Pandas DataFrame으로 데이터 처리\n#df = pd.DataFrame(data[2:], columns=[\n#    'registered_date', '출고날짜', '고객명', '연락처', '주문번호', '주소', '구매품목',\n#    '도어락', '도어벨', '조명스위치', '커튼', '내용확인', '기사님성함', '해피콜예정일', \n#    '설치예정일', '설치완료여부', '유상', '비고_아카라', '비고_피엘'\n#])\n\n목적: Google Sheets에서 불러온 데이터를 Pandas DataFrame으로 변환합니다.\n컬럼 지정: 3번째 행부터 데이터를 읽고, 컬럼을 수동으로 지정해 DataFrame을 구성합니다.\n\n\n\n3.3.3.2 데이터 형식 변환 및 처리\n\n날짜 변환: 날짜 형식의 데이터를 pd.to_datetime()을 사용해 변환하며, 변환이 불가능한 값은 NaT로 설정합니다.\n\n#df['registered_date'] = pd.to_datetime(df['registered_date'], errors='coerce')\n#df['출고날짜'] = pd.to_datetime(df['출고날짜'], errors='coerce')\n#df['해피콜예정일'] = pd.to_datetime(df['해피콜예정일'], errors='coerce')\n#df['설치예정일'] = pd.to_datetime(df['설치예정일'], errors='coerce')\n\n숫자형 변환\n\n#boolean_columns = ['내용확인', '설치완료여부']\n#for col in boolean_columns:\n#    df[col] = df[col].apply(lambda x: True if x.lower() == 'true' else False)\n\n불리언 값 처리: 불리언 값을 처리해 ‘true’ 값을 True로, 그 외 값을 False로 변환합니다.\n\n\n\n\n3.3.4 맞춤형 커튼 설치\n\n3.3.4.1 데이터 전처리\n#data = [row[:17] for row in data]\n#header = data[0]\n#df = pd.DataFrame(data[1:], columns=header)\n\n#df.rename(columns={'665': '플랫폼', '날짜': 'registered_date'}, inplace=True)\n#df = df[df['플랫폼'].notna() & df['플랫폼'].str.strip().astype(bool) &\n#        df['상품주문번호'].notna() & df['상품주문번호'].str.strip().astype(bool) &\n#        (df['상품주문번호'] != '본사 촬영용')]\n\n#df.reset_index(drop=True, inplace=True)\n\n데이터 전처리: 불필요한 컬럼을 제외하고 첫 17개의 컬럼만 선택합니다.\n컬럼명 변경: ’665’라는 컬럼명을 ’플랫폼’으로, ’날짜’라는 컬럼명을 ’registered_date’로 변경합니다.\n필터링: ‘플랫폼’과 ‘상품주문번호’가 비어 있지 않은 행만 필터링하고, ‘본사 촬영용’ 데이터를 제외합니다.\n인덱스 초기화: 불필요한 인덱스를 제거하고 새로 설정합니다.\n\n\n\n3.3.4.2 날짜 처리\n#def adjust_year(date_str, index):\n#    try:\n#        date_obj = datetime.strptime(date_str, \"%m/%d\")\n#    except ValueError:\n#        return None\n    \n#    if index &lt;= 262:\n#        return date_obj.replace(year=2023)\n#    else:\n#        return date_obj.replace(year=2024)\n\n#df['registered_date'] = df.apply(lambda row: adjust_year(row['registered_date'], row.name), #axis=1)\n\n날짜 조정: 날짜가 “월/일” 형식일 때 해당하는 연도를 인덱스에 따라 다르게 설정합니다.\n인덱스가 262 이하일 경우 2023년, 그 외에는 2024년으로 연도를 설정합니다.\n\n\n\n\n3.3.5 도어락 설치업체 배정\n\n3.3.5.1 데이터 전처리\n#df = pd.DataFrame(data[1:])\n#df = df.iloc[:,1:22]\n#required_columns =[\n#    'registered_date', '주문처', '지역1', '지역2', '지점', '설치', '기사연락처', '비용', #'청구월', '증빙유형', \n#    '추가비용', '청구월2', '지급기안', '설치여부', '이름', '연락처', '주소', '상품명', #'상품옵션', '배송메시지', '특이사항'\n#]\n#df.columns = required_columns\n\n데이터 프레임 생성: Google Sheets에서 가져온 데이터를 Pandas DataFrame으로 변환합니다.\n필요한 컬럼 설정: 필요한 21개의 열을 선택하고, 컬럼 이름을 적절하게 설정합니다.\n\n\n\n3.3.5.2 날짜 형식 변환\n#def parse_registered_date(date_str):\n#    date_formats = ['%Y/ %m/ %d', '%Y/%m/%d', '%Y. %m. %d','%Y. %m.%d']\n#    for date_format in date_formats:\n#        try:\n#            return pd.to_datetime(date_str, format=date_format, errors='raise')\n#        except (ValueError, TypeError):\n#            continue\n#    return None\n#df['registered_date'] = df['registered_date'].apply(parse_registered_date)\n\nparse_registered_date() 함수: 다양한 날짜 형식을 처리할 수 있도록 여러 날짜 포맷을 시도하여 문자열을 datetime 형식으로 변환합니다.\n\n\n\n3.3.5.3 비용 값 처리\n#def clean_cost_value(value):\n#    if isinstance(value, str):\n#        cleaned_value = value.replace('₩', '').replace(',', '')\n#        if cleaned_value.isdigit():\n#            return float(cleaned_value)\n#        else:\n#            return None\n#    return None if pd.isna(value) else value\n\n비용 값 처리: ‘₩’ 및 ’,’를 제거하고, 숫자로 변환 가능한 값을 float 형식으로 변환합니다. 값이 숫자가 아니면 None으로 반환합니다.\n\n\n\n\n3.3.6 도어락 설치 파트너\n\n3.3.6.1 데이터 전처리\n# Add 'registered_date' column\n#registered_date = pd.to_datetime('2024.02.19')\n#df.insert(0, 'registered_date', registered_date)\n\n# 컬럼명 설정\n#required_columns = ['registered_date', '지역1', '지역2', '대리점', '담당자코드', '대표', #'연락처', '주소', '사업자등록번호', '은행', '계좌', '소유자명', '세금계산서', '플라자', #'기타']\n#df.columns = required_columns\n\n# '연락처'가 없는 행 제거 및 NaN 값을 None으로 변환\n#df['연락처'] = df['연락처'].replace(r'^\\s*$', np.nan, regex=True)\n#df = df.dropna(subset=['연락처'])\n#df = df.replace({np.nan: None})\n\n등록 날짜(registered_date)를 특정 날짜로 추가합니다.\n필요한 컬럼을 지정하고 데이터 정리 및 빈 칸 처리를 수행합니다.\nNaN 값을 Python의 None 값으로 변환하여 SQL 삽입 시 문제가 발생하지 않도록 합니다.\n\n\n\n\n3.3.7 도어락 불량 등록\n\n3.3.7.1 Pandas DataFrame 생성\n#data = sheet.get_all_values()\n#df = pd.DataFrame(data[6:])  # 데이터는 7번째 행부터 시작\n#df = df.iloc[:, 2:14]  # 3번째 열부터 14번째 열까지 사용\n#df.columns = required_columns  # 필수 열 설정\n\nGoogle Sheets에서 가져온 데이터를 Pandas DataFrame으로 변환하고, 필요한 열만 선택하여 사용합니다.\n\n\n\n3.3.7.2 데이터 전처리\n#df['registered_date'] = pd.to_datetime(df['registered_date'], errors='coerce')\n#df = df.replace(\"\", None)\n#df = df.dropna(subset=['고객명', '고객불량증상'], how='all')\n\n날짜 형식을 변환하고, 빈 문자열을 None으로 바꾸며, 고객명과 고객불량증상이 비어 있는 행은 삭제합니다.\n\n\n\n\n3.3.8",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>고객 서비스 업무 관련 구글 시트 연동</span>"
    ]
  },
  {
    "objectID": "ollama.html",
    "href": "ollama.html",
    "title": "4  Local LLM - OLLAMA",
    "section": "",
    "text": "4.1 개요\n이 문서는 Streamlit, MySQL 데이터베이스, LangChain과 Ollama LLM을 결합하여 사용자가 데이터베이스와 상호작용할 수 있는 AI 기반 챗봇을 구현한 코드에 대한 설명을 제공한다.\nCS 업무와 관련된 모든 구글시트와 아카라 카페의 내용을 MySQL DB에 데이터베이스화 하였다.\n파일 또는 웹사이트 기반으로 RAG을 진행할 수 있으나 최종 목적은 DB의 내용 기반으로 RAG하는 것이다.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Local LLM - OLLAMA</span>"
    ]
  },
  {
    "objectID": "ollama.html#ollama-설정-방법",
    "href": "ollama.html#ollama-설정-방법",
    "title": "4  Local LLM - OLLAMA",
    "section": "4.2 OLLAMA 설정 방법",
    "text": "4.2 OLLAMA 설정 방법\n\n4.2.1 HuggingFaxe-Hub 설치\n#pip install huggingface-hub\n\n\n\n4.2.2 GGUF파일 다운로드\nhttps://huggingface.co/heegyu/EEVE-Korean-Instruct-10.8B-v1.0-GGUF\n#huggingface-cli download \\\n#  heegyu/EEVE-Korean-Instruct-10.8B-v1.0-GGUF \\\n#  ggml-model-Q5_K_M.gguf \\\n#  --local-dir 본인의_컴퓨터_다운로드폴더_경로 \\\n#  --local-dir-use-symlinks False\n\n\n4.2.3 Modelfile\nEEVE-Korean-Instruct-10.8B-v1.0 예시\n\n#FROM ggml-model-Q5_K_M.gguf\n#\n#TEMPLATE \"\"\"{{- if .System }}\n#&lt;s&gt;{{ .System }}&lt;/s&gt;\n#{{- end }}\n#&lt;s&gt;Human:\n#{{ .Prompt }}&lt;/s&gt;\n#&lt;s&gt;Assistant:\n#\"\"\"\n#\n#SYSTEM \"\"\"A chat between a curious user and an artificial intelligence assistant. The #assistant gives helpful, detailed, and polite answers to the user's questions.\"\"\"\n#\n#PARAMETER stop &lt;s&gt;\n#PARAMETER stop &lt;/s&gt;\n\n\n4.2.4 OLLAMA 실행\n#ollama create EEVE-Korean-10.8B -f EEVE-Korean-Instruct-10.8B-v1.0-GGUF/Modelfile\n\n4.2.4.1 OLLAMA 모델 목록\n#ollama list\n\n\n4.2.4.2 OLLAMA 모델 실행\nollama run EEVE-Korean-10.8B:latest\n\n\n4.2.4.3 ngrok에서 터널링(포트 포워드)\n#streamlit default port: 8501\n#ngrok http localhost:8501",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Local LLM - OLLAMA</span>"
    ]
  },
  {
    "objectID": "ollama.html#환경-설정-및-streamlit-페이지-구성",
    "href": "ollama.html#환경-설정-및-streamlit-페이지-구성",
    "title": "4  Local LLM - OLLAMA",
    "section": "4.3 환경 설정 및 Streamlit 페이지 구성",
    "text": "4.3 환경 설정 및 Streamlit 페이지 구성\nfrom dotenv import load_dotenv\nload_dotenv()\n\n.env 파일에서 환경 변수를 로드하여 코드에서 민감한 정보를 안전하게 불러올 수 있다.\n\nst.set_page_config(page_title=\"MySQL DB GPT\", page_icon=\"🔒\", layout=\"wide\")\n\nStreamlit 페이지의 제목과 아이콘, 레이아웃을 설정한다.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Local LLM - OLLAMA</span>"
    ]
  },
  {
    "objectID": "ollama.html#chatcallbackhandler",
    "href": "ollama.html#chatcallbackhandler",
    "title": "4  Local LLM - OLLAMA",
    "section": "4.4 ChatCallbackHandler",
    "text": "4.4 ChatCallbackHandler\n# Custom callback handler inheriting from BaseCallbackHandler\nclass ChatCallbackHandler(BaseCallbackHandler):\n    message = \"\"\n\n    def on_llm_start(self, *args, **kwargs):\n        self.message_box = st.empty()\n\n    def on_llm_end(self, *args, **kwargs):\n        save_message(self.message, \"ai\")\n\n    def on_llm_new_token(self, token, *args, **kwargs):\n        self.message += token\n        self.message_box.markdown(self.message)\n\nLangChain의 콜백 핸들러를 사용하여 챗봇의 실시간 응답을 처리합니다. 메시지를 저장하고 업데이트하며, 실시간으로 토큰이 생성될 때마다 사용자에게 표시한다.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Local LLM - OLLAMA</span>"
    ]
  },
  {
    "objectID": "ollama.html#ollama-llm-설정",
    "href": "ollama.html#ollama-llm-설정",
    "title": "4  Local LLM - OLLAMA",
    "section": "4.5 Ollama LLM 설정",
    "text": "4.5 Ollama LLM 설정\nllm = ChatOllama(\n    model=\"EEVE-Korean-10.8B:latest\",\n    temperature=0.1,\n    streaming=True,\n    callbacks=[ChatCallbackHandler()],\n)\n\nOllama의 “EEVE-Korean-10.8B” 모델을 사용하여 질문에 답변한다.\ntemperature=0.1: 모델의 응답이 얼마나 창의적인지 조정한다.\nstreaming=True: 모델의 출력이 실시간으로 스트리밍되어 사용자에게 즉시 표시된다.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Local LLM - OLLAMA</span>"
    ]
  },
  {
    "objectID": "ollama.html#mysql-테이블-불러오기",
    "href": "ollama.html#mysql-테이블-불러오기",
    "title": "4  Local LLM - OLLAMA",
    "section": "4.6 MySQL 테이블 불러오기",
    "text": "4.6 MySQL 테이블 불러오기\ndef load_database_data(tables):\n    try:\n        connection = mysql.connector.connect(\n            host=db_host,\n            database=db_database,\n            user=db_user,\n            password=db_password,\n            charset='utf8mb4',\n            collation='utf8mb4_unicode_ci'\n        )\n\n        data_frames = {}\n        for table in tables:\n            query = f\"SELECT * FROM {table}\"\n            df = pd.read_sql(query, connection)\n            data_frames[table] = df\n\n        return data_frames\n\n    except mysql.connector.Error as err:\n        st.error(f\"Error connecting to MySQL: {err}\")\n        return None\n    finally:\n        if connection.is_connected():\n            connection.close()\n\nMySQL 데이터베이스에서 사용자가 선택한 테이블 데이터를 Pandas DataFrame으로 불러온다. 이 데이터는 AI에게 제공될 “컨텍스트”로 사용된다.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Local LLM - OLLAMA</span>"
    ]
  },
  {
    "objectID": "ollama.html#데이터-테이블-선택-및-로드",
    "href": "ollama.html#데이터-테이블-선택-및-로드",
    "title": "4  Local LLM - OLLAMA",
    "section": "4.7 데이터 테이블 선택 및 로드",
    "text": "4.7 데이터 테이블 선택 및 로드\ndef table_selector():\n    available_tables = [\"aqara_cafe\", \"cs_table\", \"doorlock_malfunction_ledger\", \"curtain_ledger\", \"installation_ledger\", \"service_ledger\"]\n    selected_tables = st.sidebar.multiselect(\"Select tables to load\", available_tables, default=available_tables)\n    \n    load_button = st.sidebar.button(\"Load selected tables\")\n    \n    if load_button:\n        data_frames = load_database_data(selected_tables)\n        st.session_state[\"data_frames\"] = data_frames\n        st.success(f\"Loaded data for tables: {', '.join(selected_tables)}\")\n\n    return st.session_state.get(\"data_frames\", {})\n\n사용자가 MySQL 데이터베이스에서 불러올 테이블을 선택할 수 있게 한다. Streamlit의 multiselect 위젯을 사용하여 여러 테이블을 선택하고, 그 데이터를 로드하여 session state에 저장한다.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Local LLM - OLLAMA</span>"
    ]
  },
  {
    "objectID": "ollama.html#참고-1-file-embedding-하기",
    "href": "ollama.html#참고-1-file-embedding-하기",
    "title": "4  Local LLM - OLLAMA",
    "section": "4.8 (참고 1) File Embedding 하기",
    "text": "4.8 (참고 1) File Embedding 하기\ndef embed_file(file):\n    # Define the directory path\n    directory = \"./private_files/\"\n    \n    # Create the directory if it does not exist\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n    \n    # Save the file to the directory\n    file_path = os.path.join(directory, file.name)\n    \n    with open(file_path, \"wb\") as f:\n        f.write(file.read())\n    \n    cache_dir = LocalFileStore(f\"./private_embeddings/{file.name}\")\n    splitter = CharacterTextSplitter.from_tiktoken_encoder(\n        separator=\"\\n\",\n        chunk_size=600,\n        chunk_overlap=100,\n    )\n    \n    loader = UnstructuredFileLoader(file_path)\n    docs = loader.load_and_split(text_splitter=splitter)\n    \n    embeddings = OllamaEmbeddings(model=\"EEVE-Korean-10.8B:latest\")\n    cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n    \n    vectorstore = FAISS.from_documents(docs, cached_embeddings)\n    retriever = vectorstore.as_retriever()\n    \n    return retriever",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Local LLM - OLLAMA</span>"
    ]
  },
  {
    "objectID": "ollama.html#참고-2-webpage-embedding-하기",
    "href": "ollama.html#참고-2-webpage-embedding-하기",
    "title": "4  Local LLM - OLLAMA",
    "section": "4.9 (참고 2) Webpage Embedding 하기",
    "text": "4.9 (참고 2) Webpage Embedding 하기\n# Function to scrape website pages and extract text\ndef scrape_website(url):\n    visited_urls = set()\n    base_url = url\n    texts = []\n\n    def scrape_page(current_url):\n        if current_url in visited_urls or not current_url.startswith(base_url):\n            return\n        visited_urls.add(current_url)\n\n        # Request the page\n        response = requests.get(current_url)\n        soup = BeautifulSoup(response.content, \"html.parser\")\n\n        # Extract text from the page\n        page_text = soup.get_text(separator=\"\\n\").strip()\n        texts.append(page_text)\n\n        # Find all links on the page and recursively scrape them\n        for link in soup.find_all(\"a\", href=True):\n            absolute_link = requests.compat.urljoin(base_url, link['href'])\n            if absolute_link not in visited_urls:\n                scrape_page(absolute_link)\n\n    scrape_page(base_url)\n    return texts",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Local LLM - OLLAMA</span>"
    ]
  },
  {
    "objectID": "ollama.html#대화-기록-저장-및-표시",
    "href": "ollama.html#대화-기록-저장-및-표시",
    "title": "4  Local LLM - OLLAMA",
    "section": "4.10 대화 기록 저장 및 표시",
    "text": "4.10 대화 기록 저장 및 표시\n# Function to save the conversation history\ndef save_message(message, role):\n    if \"messages\" not in st.session_state:\n        st.session_state[\"messages\"] = []\n    st.session_state[\"messages\"].append({\"message\": message, \"role\": role})\n\nStreamlit의 session state를 사용하여 사용자와 AI 간의 대화 기록을 저장하고 페이지를 새로고침해도 대화 기록이 유지되도록 한다.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Local LLM - OLLAMA</span>"
    ]
  },
  {
    "objectID": "ollama.html#질문과-데이터-기반-응답-처리",
    "href": "ollama.html#질문과-데이터-기반-응답-처리",
    "title": "4  Local LLM - OLLAMA",
    "section": "4.11 질문과 데이터 기반 응답 처리",
    "text": "4.11 질문과 데이터 기반 응답 처리\nprompt = ChatPromptTemplate.from_template(\n    \"\"\"Answer the question using ONLY the following context and not your training data.\n    If you don't know the answer just say you don't know. DON'T make anything up.\n    \n    Context: {context}\n    Question: {question}\n    \"\"\"\n)\n\nLangChain의 ChatPromptTemplate을 사용하여 AI가 훈련 데이터가 아닌, 제공된 데이터(컨텍스트)를 기반으로만 질문에 답변하도록 한다.\n\nmessage = st.chat_input(\"Ask anything about your database...\")\n...\nchain = (\n    {\n        \"context\": RunnableLambda(lambda _: context),\n        \"question\": RunnablePassthrough(),\n    }\n    | prompt\n    | llm\n)\nwith st.chat_message(\"ai\"):\n    chain.invoke(message)\n\n사용자의 질문을 입력받고, 데이터베이스에서 가져온 컨텍스트와 함께 AI에게 전달하여 답변을 생성한다.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Local LLM - OLLAMA</span>"
    ]
  },
  {
    "objectID": "ollama.html#전체-워크플로우",
    "href": "ollama.html#전체-워크플로우",
    "title": "4  Local LLM - OLLAMA",
    "section": "4.12 전체 워크플로우",
    "text": "4.12 전체 워크플로우\n\n사용자는 MySQL 데이터베이스 테이블을 선택한다..\n선택된 데이터가 Pandas DataFrame으로 불러온다..\n사용자가 질문을 입력하면, AI가 데이터베이스에서 가져온 데이터를 바탕으로 답변을 제공한다.\n대화 기록이 유지되며, 이전 대화 내용을 확인할 수 있다.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Local LLM - OLLAMA</span>"
    ]
  },
  {
    "objectID": "database.html",
    "href": "database.html",
    "title": "5  Database - MySQL",
    "section": "",
    "text": "5.1 개요\nCS 작업 관련 모든 구글시트, 아카라 카페, 기술지원 내역을 MySQL DB에 데이터 베이스화 하였다.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Database - MySQL</span>"
    ]
  },
  {
    "objectID": "database.html#db-schema",
    "href": "database.html#db-schema",
    "title": "5  Database - MySQL",
    "section": "5.2 DB Schema",
    "text": "5.2 DB Schema\nDatabase: cs\n\n\n\n\n\n\n5.2.1 아카라 카페\n\n\n\n\n\n\n\n5.2.2 기술 CS 업무\n\n\n\n\n\n\n\n5.2.3 수거 신청 대장\n\n\n\n\n\n\n\n5.2.4 커튼/블라인드 설치\n\n\n\n\n\n\n\n5.2.5 도어락 설치기사 배정\n\n\n\n\n\n\n\n5.2.6 도어락 설치 파트너\n\n\n\n\n\n\n\n5.2.7 도어락 불량 대장\n\n\n\n\n\n\n\n5.2.8 업무일지",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Database - MySQL</span>"
    ]
  },
  {
    "objectID": "database.html#mysql-테이블-생성-방법",
    "href": "database.html#mysql-테이블-생성-방법",
    "title": "5  Database - MySQL",
    "section": "5.3 MySQL 테이블 생성 방법",
    "text": "5.3 MySQL 테이블 생성 방법\n도어락 설치 기사 배정 테이블 예제\n#CREATE TABLE doorlock_installation_ledger (\n#    id INT AUTO_INCREMENT PRIMARY KEY,\n#    registered_date DATETIME,\n#    주문처 VARCHAR(255),\n#    지역1 VARCHAR(255),\n#    지역2 VARCHAR(255),\n#    지점 VARCHAR(255),\n#    설치 VARCHAR(255),\n#    기사연락처 VARCHAR(20),\n#    비용 DECIMAL(10, 2),\n#    청구월 VARCHAR(50),\n#    증빙유형 VARCHAR(50),\n#    추가비용 DECIMAL(10, 2),\n#    청구월2 VARCHAR(50),\n#    지급기안 VARCHAR(50),\n#    설치여부 BOOLEAN,\n#    이름 VARCHAR(255),\n#    연락처 VARCHAR(20),\n#    주소 VARCHAR(255),\n#    상품명 VARCHAR(255),\n#    상품옵션 VARCHAR(255),\n#    배송메시지 TEXT,\n#    특이사항 TEXT,\n#    UNIQUE KEY unique_record (registered_date, 연락처,주소)\n#) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;\n\nUnique Key 설정: 위 예제에서 보며 registered_date, 연락처와 주소 3개의 칼럼이 같을 경우는 새로운 row를 추가하지 않고 업데이트하도록 unique key를 설정합니다.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Database - MySQL</span>"
    ]
  },
  {
    "objectID": "database.html#코드-분석",
    "href": "database.html#코드-분석",
    "title": "5  Database - MySQL",
    "section": "5.4 코드 분석",
    "text": "5.4 코드 분석\n\n5.4.1 MySQL DB 연결\n#conn = mysql.connector.connect(\n#    user=os.getenv('SQL_USER'),\n#    password=os.getenv('SQL_PASSWORD'),\n#    host=os.getenv('SQL_HOST'),\n#    database=os.getenv('SQL_DATABASE'),\n#    charset='utf8mb4',\n#    collation='utf8mb4_general_ci'\n#)\n\n\n환경 변수에서 가져온 자격 증명으로 MySQL 데이터베이스에 연결을 설정한다. charset과 collation을 UTF-8로 설정해 한국어와 같은 문자를 적절히 처리할 수 있게 한다.\n\n\n\n5.4.2 아카라 카페\n\n5.4.2.1 데이터 저장\n#def save_to_mysql(self, df):\n#    \"\"\"Save DataFrame to MySQL database.\"\"\"\n#    try:\n#        # Connect to MySQL database\n#       conn = mysql.connector.connect(**self.db_config)\n#       cursor = conn.cursor()\n#\n#        # Replace NaN with None for MySQL compatibility\n#        df = df.where(pd.notnull(df), None)\n#        # Insert data into MySQL, checking for duplicates\n#       for _, row in df.iterrows():\n#            # Check if the row already exists\n#            check_sql = \"\"\"\n#            SELECT COUNT(*) FROM aqara_cafe WHERE registered_date = %s AND title = %s\n#            \"\"\"\n#            cursor.execute(check_sql, (row['registered_date'], row['title']))\n#            result = cursor.fetchone()\n#\n#            if result[0] == 0:  # If no existing row found\n#                insert_sql = \"\"\"\n#                INSERT INTO aqara_cafe (registered_date, devices, title, question, answers)\n#                VALUES (%s, %s, %s, %s, %s)\n#                \"\"\"\n#               cursor.execute(insert_sql, tuple(row))\n#        \n#        conn.commit()\n#       cursor.close()\n#        conn.close()\n#        print(\"Data saved to MySQL successfully!\")\n#   except mysql.connector.Error as err:\n#        print(f\"Error: {err}\")\n\nsave_to_mysql() 함수는 크롤링한 데이터를 MySQL 데이터베이스에 저장하는 역할을 한다.\nNaN처리: df.where(pd.notnull(df), None): MySQL에서는 NaN 값을 NULL로 처리해야 합니다. 이 부분에서 DataFrame의 NaN 값을 MySQL에 호환되는 None으로 변환합니다.\n\n\n\n5.4.2.2 중복 데이터 확인및 처리\nSELECT COUNT(*) FROM aqara_cafe WHERE registered_date = %s AND title = %s\n\n이 쿼리는 테이블에서 등록된 날짜와 제목이 같은 데이터를 확인하는 쿼리입니다. 이를 통해 중복된 데이터가 있는지 확인한다.\ncursor.execute(check_sql, (row[‘registered_date’], row[‘title’])): row[‘registered_date’]와 row[‘title’] 값을 사용하여 중복 여부를 검사한다.\n\n\n\n5.4.2.3 데이터 삽입\n#INSERT INTO aqara_cafe (registered_date, devices, title, question, answers)\n#VALUES (%s, %s, %s, %s, %s)\n\n이 쿼리는 MySQL 테이블 aqara_cafe에 데이터를 삽입하는 SQL 문이다. 각 행의 데이터를 테이블에 삽입한다.\ncursor.execute(insert_sql, tuple(row)): 각 행의 데이터를 SQL 쿼리의 %s 자리에 삽입해 MySQL에 추가한다.\n\n\n\n\n5.4.3 \n수거 신청 대장\n\n5.4.3.1 기존 데이터 유무 확인\n#check_query = \"\"\"\n#SELECT COUNT(*) FROM service_ledger \n#WHERE registered_date = %s AND 고객명 = %s AND 주문번호 = %s AND 제품 = %s\n#\"\"\"\n#cursor.execute(check_query, (row['registered_date'], row['고객명'], row['주문번호'], row['제품']))\n#result = cursor.fetchone()\n\n동일한 registered_date, 고객명, 주문번호, 그리고 제품을 가진 레코드가 이미 존재하는지 확인한다.\ncursor.execute()로 쿼리를 실행하고, cursor.fetchone()으로 결과를 가져온다.\n\n\n\n5.4.3.2 업데이트 로직\n#if result[0] &gt; 0:\n#    update_query = \"\"\"\n#    UPDATE service_ledger \n#    SET 완료 = %s, 작성자 = %s, 구분 = %s, 사유 = %s, 배송비 = %s, ...\n#    WHERE registered_date = %s AND 고객명 = %s AND 주문번호 = %s AND 제품 = %s\n#    \"\"\"\n#    cursor.execute(update_query, ...)\n#else:\n#    insert_query = \"\"\"\n#    INSERT INTO service_ledger (완료, registered_date, 작성자, 구분, 사유, ...) \n#    VALUES (%s, %s, %s, %s, ...)\n#    \"\"\"\n#    cursor.execute(insert_query, ...)\n\n업데이트 로직: 만약 동일한 레코드가 존재하면, 기존의 레코드를 UPDATE 쿼리를 사용해 업데이트합니다.\n삽입 로직: 동일한 레코드가 존재하지 않으면, 새로운 레코드를 INSERT 쿼리를 사용해 삽입합니다.\n\n\n\n\n5.4.4 설치 기사 배정\n\n5.4.4.1 데이터 삽입 및 업데이트 쿼리\n#for index, row in df.iterrows():\n#    if row['주문번호'] and pd.notna(row['주문번호']):\n#        sql = \"\"\"\n#            INSERT INTO installation_ledger \n#            (registered_date, 출고날짜, 고객명, 연락처, 주문번호, 주소, 구매품목,\n#            도어락, 도어벨, 조명스위치, 커튼, 내용확인, 기사님성함, 해피콜예정일, \n#            설치예정일, 설치완료여부, 유상, 비고_아카라, 비고_피엘)\n#            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, #%s)\n#           ON DUPLICATE KEY UPDATE\n#            registered_date = VALUES(registered_date),\n#            출고날짜 = VALUES(출고날짜),\n#            고객명 = VALUES(고객명),\n#           연락처 = VALUES(연락처),\n#            주소 = VALUES(주소),\n#            구매품목 = VALUES(구매품목),\n#            도어락 = VALUES(도어락),\n#            도어벨 = VALUES(도어벨),\n#            조명스위치 = VALUES(조명스위치),\n#            커튼 = VALUES(커튼),\n#            내용확인 = VALUES(내용확인),\n#            기사님성함 = VALUES(기사님성함),\n#            해피콜예정일 = VALUES(해피콜예정일),\n#            설치예정일 = VALUES(설치예정일),\n#            설치완료여부 = VALUES(설치완료여부),\n#            유상 = VALUES(유상),\n#            비고_아카라 = VALUES(비고_아카라),\n#            비고_피엘 = VALUES(비고_피엘)\n#        \"\"\"\n#        values = (\n#            row['registered_date'], row['출고날짜'], row['고객명'], row['연락처'], #row['주문번호'], row['주소'], row['구매품목'],\n#            row['도어락'], row['도어벨'], row['조명스위치'], row['커튼'], row['내용확인'], #row['기사님성함'], row['해피콜예정일'],\n#            row['설치예정일'], row['설치완료여부'], row['유상'], row['비고_아카라'], #row['비고_피엘']\n#        )\n#        \n#       cursor.execute(sql, values)\n\ndf.iterrows()를 사용해 DataFrame의 각 행을 순회하며, 주문번호가 존재하는 경우에만 MySQL에 데이터를 삽입 또는 업데이트합니다.\n쿼리 설명:\n\nINSERT INTO installation_ledger: 데이터를 삽입하는 SQL 쿼리입니다.\nON DUPLICATE KEY UPDATE: 만약 중복된 키(예: 주문번호)가 있으면 기존 데이터를 업데이트합니다.\nVALUES(): 각 행의 데이터를 SQL 쿼리로 전달합니다.\n\n\n\n\n\n5.4.5 커튼/블라인드 설치\n#insert_query = \"\"\"\n#    INSERT INTO curtain_ledger \n#    (registered_date, 플랫폼, 상품주문번호, 상품명, 수량, 수취인명, 수취인연락처1, \n#     수취인연락처2, 배송지, 구매자연락처, 우편번호, 배송메세지, 옵션정보, \n#     옵션관리코드, 배송방법, 택배사, 송장번호)\n#    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n#    ON DUPLICATE KEY UPDATE\n#    registered_date = VALUES(registered_date),\n#    플랫폼 = VALUES(플랫폼),\n#    상품명 = VALUES(상품명),\n#    수량 = VALUES(수량),\n#    수취인명 = VALUES(수취인명),\n#    수취인연락처1 = VALUES(수취인연락처1),\n#   수취인연락처2 = VALUES(수취인연락처2),\n#    배송지 = VALUES(배송지),\n#    구매자연락처 = VALUES(구매자연락처),\n#    우편번호 = VALUES(우편번호),\n#    배송메세지 = VALUES(배송메세지),\n#    옵션정보 = VALUES(옵션정보),\n#    옵션관리코드 = VALUES(옵션관리코드),\n#    배송방법 = VALUES(배송방법),\n#    택배사 = VALUES(택배사),\n#    송장번호 = VALUES(송장번호)\n#\"\"\"\n\nSQL 쿼리: INSERT INTO 구문을 사용하여 데이터를 삽입합니다. 동시에 ON DUPLICATE KEY UPDATE를 사용하여 중복된 키가 있을 경우 기존 데이터를 업데이트합니다.\n\n\n5.4.5.1 트랜잭션 재시도 및 커밋\n#retry_count = 3\n#for index, row in df.iterrows():\n#    # 수량이 빈 값이거나 숫자로 변환할 수 없으면 0으로 처리\n#    try:\n#        quantity = int(row['수량']) if row['수량'].strip() else 0\n#    except ValueError:\n#        quantity = 0\n#    \n#    values = (row['registered_date'], row['플랫폼'], row['상품주문번호'], row['상품명'], #uantity, ...)\n#   \n#    for attempt in range(retry_count):\n#        try:\n#            cursor.execute(insert_query, values)\n#            break  # 성공 시 루프 탈출\n#        except mysql.connector.Error as err:\n#            if err.errno == 1205:  # Lock wait timeout\n#                st.write(f\"Lock wait timeout, 재시도 중: {attempt + 1}\")\n#               time.sleep(2)  # 잠시 대기 후 재시도\n#           else:\n#                raise  # 다른 오류 발생 시\n#\n#cursor.close()\n#conn.close()\n\n재시도 로직: MySQL에서 트랜잭션이 실패할 경우(예: 잠금 대기 시간 초과) 최대 3번까지 재시도합니다.\n트랜잭션 처리: 각 데이터 행을 MySQL에 삽입 또는 업데이트합니다.\n\n\n\n\n5.4.6 도어락 설치 기사 배정\n\n5.4.6.1 데이터 삽입 또는 업데이트 쿼리\n#query = \"\"\"\n#INSERT INTO doorlock_installation_ledger (\n#    registered_date, 주문처, 지역1, 지역2, 지점, 설치, 기사연락처, 비용, 청구월, 증빙유형, #추가비용, 청구월2, 지급기안, 설치여부, 이름, 연락처, 주소, 상품명, 상품옵션, 배송메시지, #특이사항\n#) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n#ON DUPLICATE KEY UPDATE\n#    주문처 = VALUES(주문처),\n#    지역1 = VALUES(지역1),\n#    지역2 = VALUES(지역2),\n#    지점 = VALUES(지점),\n#    설치 = VALUES(설치),\n#    기사연락처 = VALUES(기사연락처),\n#    비용 = VALUES(비용),\n#    청구월 = VALUES(청구월),\n#    증빙유형 = VALUES(증빙유형),\n#    추가비용 = VALUES(추가비용),\n#    청구월2 = VALUES(청구월2),\n#    지급기안 = VALUES(지급기안),\n#    설치여부 = VALUES(설치여부),\n#    이름 = VALUES(이름),\n#    상품명 = VALUES(상품명),\n#    상품옵션 = VALUES(상품옵션),\n#    배송메시지 = VALUES(배송메시지),\n#    특이사항 = VALUES(특이사항)\n#\"\"\"\n\nSQL 쿼리: INSERT INTO 구문을 사용하여 데이터를 삽입하고, 중복 키가 발생할 경우 기존 데이터를 업데이트하는 ON DUPLICATE KEY UPDATE 구문을 사용합니다.\n\n\n\n5.4.6.2 데이터 삽입 또는 업데이트 처리\n#def insert_or_update_data(df):\n#    try:\n#        for index, row in df.iterrows():\n#            values = [\n#                row['registered_date'].strftime('%Y-%m-%d %H:%M:%S') if #row['registered_date'] else None,\n#                row['주문처'], row['지역1'], row['지역2'], row['지점'], row['설치'], #row['기사연락처'],\n#                clean_cost_value(row['비용']), row['청구월'], row['증빙유형'], #clean_cost_value(row['추가비용']),\n#                row['청구월2'], row['지급기안'], 1 if row['설치여부'] == 'TRUE' else 0,\n#                row['이름'], row['연락처'], row['주소'], row['상품명'], row['상품옵션'], #row['배송메시지'], row['특이사항']\n#            ]\n#            cursor.execute(query, values)\n#        conn.commit()\n#        st.write(\"데이터가 성공적으로 MySQL에 저장되었거나 업데이트되었습니다.\")\n#    except Error as e:\n#        st.write(f\"Error while connecting to MySQL: {e}\")\n#    finally:\n#        cursor.close()\n#        conn.close()\n\n데이터 삽입/업데이트: 각 데이터 행을 INSERT INTO 쿼리를 통해 MySQL에 삽입하거나 업데이트한다.\n\n\n\n\n5.4.7 도어락 설치 파트너\n\n5.4.7.1 데이터 삽입 및 업데이트 쿼리\n#query = \"\"\"\n#INSERT INTO doorlock_installation_partners (\n#    registered_date, 지역1, 지역2, 대리점, 담당자코드, 대표, 연락처, 주소,\n#    사업자등록번호, 은행, 계좌, 이름, 세금계산서, 플라자, 기타\n#) VALUES (\n#    %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s\n#) ON DUPLICATE KEY UPDATE\n#    지역1 = VALUES(지역1),\n#    담당자코드 = VALUES(담당자코드),\n#    대표 = VALUES(대표),\n#    연락처 = VALUES(연락처),\n#   사업자등록번호 = VALUES(사업자등록번호),\n#   은행 = VALUES(은행),\n#    계좌 = VALUES(계좌),\n#   이름 = VALUES(이름),\n#    세금계산서 = VALUES(세금계산서),\n#   플라자 = VALUES(플라자),\n#   기타 = VALUES(기타);\n#\"\"\n#\n#def insert_or_update_data(df):\n#   try:\n#        for index, row in df.iterrows():\n#            values = [\n#                row['registered_date'].strftime('%Y-%m-%d %H:%M:%S') if #row['registered_date'] else None,\n#                row['지역1'], row['지역2'], row['대리점'], row['담당자코드'], row['대표'], #row['연락처'], \n#               row['주소'], row['사업자등록번호'], row['은행'], row['계좌'], row['소유자명'],row['세금계산서'], row['플라자'], row['기타']\n#            ]\n#            cursor.execute(query, values)\n#        conn.commit()\n#        st.write(\"데이터가 성공적으로 MySQL에 저장되었거나 업데이트되었습니다.\")\n#    except Error as e:\n#        st.write(f\"Error while connecting to MySQL: {e}\")\n#    finally:\n#        cursor.close()\n#        conn.close()\n\nINSERT INTO 및 ON DUPLICATE KEY UPDATE: 데이터베이스에 데이터를 삽입할 때, 만약 기존에 동일한 키(예: 연락처)가 존재하면 해당 데이터를 업데이트한다. 그렇지 않으면 새로운 데이터를 삽입한다.\n데이터 삽입: 각 행의 데이터를 SQL 쿼리에 맞춰 준비하고, 반복문을 통해 각 행의 데이터를 MySQL 테이블에 삽입하거나 업데이트한다.\n트랜잭션 커밋: conn.commit()을 통해 데이터베이스에 변경 사항을 커밋하여 저장한다.\n\n\n\n\n5.4.8 도어락 불량 대장\n\n5.4.8.1 데이터 삽입 및 업데이트 쿼리\n#query = \"\"\"\n#INSERT INTO doorlock_malfunction_ledger (registered_date, ..., 비고)\n#VALUES (%s, %s, ..., %s)\n#ON DUPLICATE KEY UPDATE 접수채널 = VALUES(접수채널), ..., 비고 = VALUES(비고);\n#\"\"\"\n\nINSERT INTO … ON DUPLICATE KEY UPDATE 구문을 사용하여, 동일한 고객명과 고객연락처에 해당하는 데이터가 이미 존재할 경우, 기존 데이터를 업데이트하고, 없으면 새 데이터를 삽입한다.\n\n#for index, row in df.iterrows():\n#    values = [\n#        row['registered_date'].strftime('%Y-%m-%d %H:%M:%S') if row['registered_date'] else #None,\n#        ...\n#    ]\n#    cursor.execute(query, values)\n#conn.commit()\n\n데이터프레임의 각 행에 대해 쿼리를 실행하여, MySQL에 데이터를 삽입하거나 업데이트한다.\n\n\n\n\n5.4.9 업무일지\n\n5.4.9.1 주요기능\n\n데이터 업데이트: 동일한 날짜와 업무 유형의 데이터가 있을 경우, 기존 데이터를 업데이트하고 없으면 새로 추가한다.\n데이터 조회 및 자동 입력: 기존 데이터를 조회하여 폼에 미리 입력해 사용자 경험을 개선한다.\n\n\n\n5.4.9.2 MySQL 데이터 검색\n#cursor.execute(\"\"\"\n#    SELECT 업무유형, 작업자, 업무일지, 비고 \n#    FROM work_journal \n#    WHERE DATE(registered_date) = %s AND 업무유형 = %s\n#\"\"\", (registered_date_for_query, task_type))\n#existing_data = cursor.fetchone()\n\n데이터베이스에서 선택된 날짜와 업무 유형에 해당하는 기존 데이터를 조회하여 있으면 폼에 자동으로 채운다.\n\n\n\n5.4.9.3 MySQL 데이터 저장\n#cursor.execute(\"\"\"\n#    INSERT INTO work_journal (registered_date, 업무유형, 작업자, 업무일지, 비고) \n#    VALUES (%s, %s, %s, %s, %s)\n#\"\"\", (registered_date_for_db, task_type, worker, work_journal, note))\n\nMySQL에도 동일한 방식으로 데이터를 삽입하거나 업데이트한다.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Database - MySQL</span>"
    ]
  },
  {
    "objectID": "cafe24.html",
    "href": "cafe24.html",
    "title": "6  아카라라이프 자사몰(카페24) API 연동",
    "section": "",
    "text": "6.1 인증 절차 및 API 활용",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>아카라라이프 자사몰(카페24) API 연동</span>"
    ]
  },
  {
    "objectID": "cafe24.html#인증-절차-및-api-활용",
    "href": "cafe24.html#인증-절차-및-api-활용",
    "title": "6  아카라라이프 자사몰(카페24) API 연동",
    "section": "",
    "text": "6.1.1 인증 절차 및 API 개요\n\n\n\n\n\n[참고 사이트]\n#Client ID/Secret 얻는 방법: https://velog.io/(yl9517/Cafe24-Authentication?)-#%EC%9D%B8%EC%A6%9D%EB%B6%80%ED%84%B0-API-%ED%98%B8%EC%B6%9C%EA%B9%8C%EC%A7%80\n\n\n6.1.2 Authorization Code 획득\nMall ID, Client ID와 Client Secret 필요\n\n# To get authentication code\n\nimport requests\nimport base64\nfrom urllib.parse import urlparse, parse_qs\n\nmall_id = \"xxxxxxx\"\nclient_id = \"xxxxxxxx\"\nclient_secret = \"xxxxxx\"\nstate = \"12345\"\nredirect_uri = \"https://xxxx.com\"\nscope = \"mall.read_product,mall.read_application,mall.write_application,mall.read_community,mall.write_community\"\n\n# 요청을 보낼 URL 설정\nurl = f\"https://{mall_id}.cafe24api.com/api/v2/oauth/authorize?response_type=code&client_id={client_id}&state={state}&redirect_uri={redirect_uri}&scope={scope}\"\n\nprint(url)\n\n# GET 요청 보내기\nresponse = requests.get(url)\n\n# 응답 확인\nif response.status_code == 302:\n    # Location 헤더에서 authorize_code 추출\n    redirect_url = response.headers['Location']\n    parsed_url = urlparse(redirect_url)\n    authorize_code = parse_qs(parsed_url.query)['code'][0]\n    print(\"Authorize Code:\", authorize_code)\nelse:\n    print(\"Authorization failed:\", response.text)\n\n\n6.1.3 Access Token 획득\n위에서 획득한 authorization code 사용\nimport requests\n\nmall_id = \"xxxxxxx\"\nclient_id = \"xxxxxxxx\"\nclient_secret = \"xxxxxx\"\nstate = \"12345\"\nredirect_uri = \"https://xxxx.com\"\nscope = \"mall.read_product,mall.read_application,mall.write_application,mall.read_community,mall.write_community\"\n\nauthorization_code =\"xxxxxxxx\"\n\n\n# 기본 인증 정보 생성\nbasic_auth = f\"{client_id}:{client_secret}\"\nencoded_basic_auth = base64.b64encode(basic_auth.encode()).decode()\n\n# 요청 URL 및 데이터\nurl = f\"https://{mall_id}.cafe24api.com/api/v2/oauth/token\"\nheaders = {\n    'Authorization': f\"Basic {encoded_basic_auth}\",\n    'Content-Type': 'application/x-www-form-urlencoded'\n}\ndata = {\n    'grant_type': 'authorization_code',\n    'code': authorization_code,\n    'redirect_uri': redirect_uri\n}\n\n# POST 요청 보내기\nresponse = requests.post(url, headers=headers, data=data)\n\n# 응답 확인\nprint(response.json())\n\n\n\n6.1.4 Token 갱신하기\nimport requests\nimport base64\n\n# 변수 설정\nmall_id = \"xxxxxxx\"\nclient_id = \"xxxxxxxx\"\nclient_secret = \"xxxxxx\"\n\n# 기본 인증 정보 생성\nbasic_auth = f\"{client_id}:{client_secret}\"\nencoded_basic_auth = base64.b64encode(basic_auth.encode()).decode()\n\n# 요청 URL 설정\nurl = f\"https://{mall_id}.cafe24api.com/api/v2/oauth/token\"\nheaders = {\n    'Authorization': f\"Basic {encoded_basic_auth}\",\n    'Content-Type': 'application/x-www-form-urlencoded'\n}\n\n# refresh.csv 파일에서 refresh token 값을 읽어옴\nwith open('refresh.csv', 'r') as file:\n    refresh_token = file.read().strip()\n    \nrefresh_token =\"l2S54kScJFRrljTKxlZE8B\"\n# 요청 데이터 설정\ndata = {\n    'grant_type': 'refresh_token',\n    'refresh_token': refresh_token\n}\n\n# POST 요청 보내기\nresponse = requests.post(url, headers=headers, data=data)\n\n# access_token 및 refresh_token 값 읽어오기\nif response.status_code == 200:\n    response_data = response.json()\n    access_token = response_data['access_token']\n    refresh_token = response_data['refresh_token']\n    print(\"Access Token:\", access_token)\n    print(\"Refresh Token:\", refresh_token)\n    print(response.json())\n    # refresh token을 CSV 파일에 저장\n    with open('refresh.csv', 'w') as file:\n        file.write(refresh_token)\nelse:\n    print(\"Error:\", response.text)\n\n\n\n6.1.5 게시판 읽어오기 - 상품 게시판\nimport requests\nimport re\nimport datetime\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\nbulletin = 6\nurl = f\"https://aqarakr.cafe24api.com/api/v2/admin/boards/{bulletin}/articles\"\n\ninterval=60 # 오늘부터 며칠 전까지?\npayload = {}\nfiles = {}\nheaders = {\n    'Authorization': f'Bearer {access_token}',\n    'X-Cafe24-Api-Version': '2024-03-01',\n    'Content-Type': 'application/json',\n    'Cookie': 'xxxxxxxxxxx'\n}\n\n# 현재 날짜를 가져옵니다.\ncurrent_date = datetime.datetime.now()\n\n# end_date로부터 7일 전의 날짜를 구합니다.\nstart_date = current_date - datetime.timedelta(days=interval)\n\n# 날짜를 원하는 형식으로 포맷팅합니다.\nstart_date_str = start_date.strftime('%Y-%m-%d')\nend_date_str = current_date.strftime('%Y-%m-%d')\n\ncurrent_date = datetime.datetime.now().strftime('%Y-%m-%d')\n\nparams = {\n    'start_date': start_date_str,\n    'end_date': end_date_str\n}\n\nresponse = requests.request(\"GET\", url, headers=headers, data=payload, files=files,params=params)\ndata = response.json()\n\narticles_data = []\nfor article in data['articles']:\n    # 각 기사의 날짜 가져오기\n    article_date = article['created_date']\n    # 해당 날짜의 기사 내용 가져오기\n    content = article['content']\n    text = BeautifulSoup(content, \"html.parser\").get_text()\n    articles_data.append({'date': article_date, 'text': text})\n    #print(f\"Date: {article_date}\")\n    #print(text)\ndf = pd.DataFrame(articles_data)\nprint(df.head())\n\n\n6.1.6 게시판 읽어오기 - 1:1 게시판\nbulletin = 9\nurl = f\"https://aqarakr.cafe24api.com/api/v2/admin/boards/{bulletin}/articles\"\n\ninterval=60 # 오늘부터 며칠 전까지?\npayload = {}\nfiles = {}\nheaders = {\n    'Authorization': f'Bearer {access_token}',\n    'X-Cafe24-Api-Version': '2024-03-01',\n    'Content-Type': 'application/json',\n    'Cookie': 'ECSESSID=5d169e847b0b49d2ff41047129114582'\n}\n\n# 현재 날짜를 가져옵니다.\ncurrent_date = datetime.datetime.now()\n\n# end_date로부터 7일 전의 날짜를 구합니다.\nstart_date = current_date - datetime.timedelta(days=interval)\n\n# 날짜를 원하는 형식으로 포맷팅합니다.\nstart_date_str = start_date.strftime('%Y-%m-%d')\nend_date_str = current_date.strftime('%Y-%m-%d')\n\ncurrent_date = datetime.datetime.now().strftime('%Y-%m-%d')\n\nparams = {\n    'start_date': start_date_str,\n    'end_date': end_date_str\n}\n\nresponse = requests.request(\"GET\", url, headers=headers, data=payload, files=files,params=params)\ndata = response.json()\n\narticles_data = []\nfor article in data['articles']:\n    # 각 기사의 날짜 가져오기\n    article_date = article['created_date']\n    # 해당 날짜의 기사 내용 가져오기\n    content = article['content']\n    text = BeautifulSoup(content, \"html.parser\").get_text()\n    articles_data.append({'date': article_date, 'text': text})\n    #print(f\"Date: {article_date}\")\n    #print(text)\ndf = pd.DataFrame(articles_data)\nprint(df.head())",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>아카라라이프 자사몰(카페24) API 연동</span>"
    ]
  },
  {
    "objectID": "cafe24.html#주요-코드-분석",
    "href": "cafe24.html#주요-코드-분석",
    "title": "6  아카라라이프 자사몰(카페24) API 연동",
    "section": "6.2 주요 코드 분석",
    "text": "6.2 주요 코드 분석\n\n6.2.1 사용 라이브러리\nrequests, base64, dotenv, datetime, BeautifulSoup, pandas, matplotlib, konlpy 등 라이브러리:\n\nrequests: 외부 API에 HTTP 요청을 보내고 응답을 받아오는데 사용된다.\nbase64: 기본 인증에 필요한 클라이언트 ID와 시크릿을 Base64로 인코딩하는 데 사용된다.\ndotenv: 환경 변수 파일(.env)에서 설정값을 불러오기 위해 사용된다.\ndatetime: 날짜 및 시간 관련 처리를 위해 사용된다.\nBeautifulSoup: HTML에서 텍스트를 추출하는 데 사용된다.\npandas: 데이터를 테이블 형태로 저장하고 처리하기 위한 데이터프레임 라이브러리이다.\nmatplotlib: 그래프와 시각화를 그리기 위해 사용된다.\nkonlpy: 한국어 자연어 처리를 위한 라이브러리이다.\nCounter: 단어 빈도수 계산을 위해 사용된다.\n\n\n\n6.2.2 기본 인증 정보 생성\nbasic_auth = f\"{cafe24_client_id}:{cafe24_client_secret}\"\nencoded_basic_auth = base64.b64encode(basic_auth.encode()).decode()\n\ncafe24_client_id, cafe24_client_secret: dotenv로부터 불러온 API 접근에 필요한 인증 정보를 사용하여 Base64로 인코딩한다. 이 인증 정보를 사용해 API에 접근한다.\n\n\n\n6.2.3 날짜 범위 설정 및 API 요청\ncurrent_date = datetime.datetime.now()\nstart_date = current_date - datetime.timedelta(days=params_interval)\nparams = {'start_date': start_date_str, 'end_date': end_date_str, 'limit': 100}\n\n날짜 범위 설정: 현재 날짜에서 사용자 입력에 따라 지정된 일수(params_interval) 만큼 이전 날짜를 계산합니다.\nAPI 요청 파라미터: 지정된 날짜 범위와 다른 매개변수를 API 요청에 포함시킵니다.\n\n\n\n6.2.4 HTML 데이터 처리 및 텍스트 추출\ncontent = article['content']\nfiltered_text = BeautifulSoup(content, \"html.parser\").get_text()\n\nBeautifulSoup: 응답받은 HTML 형식의 데이터를 파싱하여, 텍스트를 추출합니다. 여기서는 각 게시물의 본문 내용을 필터링하여 텍스트만 추출합니다.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>아카라라이프 자사몰(카페24) API 연동</span>"
    ]
  },
  {
    "objectID": "naver_smartstore.html",
    "href": "naver_smartstore.html",
    "title": "7  네이버 스마트스토어 API 연동",
    "section": "",
    "text": "7.1 인증 절차",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>네이버 스마트스토어 API 연동</span>"
    ]
  },
  {
    "objectID": "naver_smartstore.html#인증-절차",
    "href": "naver_smartstore.html#인증-절차",
    "title": "7  네이버 스마트스토어 API 연동",
    "section": "",
    "text": "7.1.1 인증 과정 참고\n요구사항: Application ID와 Application Secret 필요\n위 애플리케이션 ID와 시크릿을 얻는 방법:\n#https://private.tistory.com/140#google_vignette\n주의:API 그룹의 경우 판매자 정보/주문 판매자/상품/문의 모두 포함\n\n\n7.1.2 액세스 토큰 생성\n\nimport time\nimport bcrypt\nimport pybase64\nimport urllib.parse\nimport requests\n\nclient_id = \"xxxxxx\"\nclient_secret = \"xxxxx\"\n\ndef get_token(client_id, client_secret):\n    try:\n        timestamp = str(int((time.time() - 3) * 1000))\n        pwd = f'{client_id}_{timestamp}'\n        hashed = bcrypt.hashpw(pwd.encode('utf-8'), client_secret.encode('utf-8'))\n        client_secret_sign = pybase64.standard_b64encode(hashed).decode('utf-8')\n\n        headers = {\"content-type\": \"application/x-www-form-urlencoded\"}\n        data_ = {\n            \"client_id\": client_id,\n            \"timestamp\": timestamp,\n            \"grant_type\": \"client_credentials\",\n            \"client_secret_sign\": client_secret_sign,\n            \"type\": \"SELF\"\n        }\n\n        # Encode data_ dictionary into a URL-encoded string\n        body = urllib.parse.urlencode(data_)\n\n        url = 'https://api.commerce.naver.com/external/v1/oauth2/token'\n        print(\"Request URL:\", url)\n        print(\"Request Body:\", body)\n\n        res = requests.post(url=url, headers=headers, data=body)\n        res.raise_for_status()  # Raise an exception for HTTP errors\n\n        res_data = res.json()\n        if 'access_token' in res_data:\n            return res_data['access_token']\n        else:\n            raise ValueError(f'Token request failed: {res_data}')\n    \n    except Exception as e:\n        print(f'Error occurred: {e}')\n        return None\n\nst_access_token = get_token(client_id=client_id, client_secret=client_secret)\nif st_access_token:\n    print(f'Issued token: {st_access_token}')\nelse:\n    print('Failed to obtain token.')",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>네이버 스마트스토어 API 연동</span>"
    ]
  },
  {
    "objectID": "naver_smartstore.html#주요-코드-분석",
    "href": "naver_smartstore.html#주요-코드-분석",
    "title": "7  네이버 스마트스토어 API 연동",
    "section": "7.2 주요 코드 분석",
    "text": "7.2 주요 코드 분석\n\n7.2.1 토큰 발급 함수 (get_token)\ndef get_token(client_id, client_secret):\n    timestamp = str(int((time.time() - 3) * 1000))\n    pwd = f'{client_id}_{timestamp}'\n    hashed = bcrypt.hashpw(pwd.encode('utf-8'), client_secret.encode('utf-8'))\n    client_secret_sign = pybase64.standard_b64encode(hashed).decode('utf-8')\n\n    headers = {\"content-type\": \"application/x-www-form-urlencoded\"}\n    data_ = {\n        \"client_id\": client_id,\n        \"timestamp\": timestamp,\n        \"grant_type\": \"client_credentials\",\n        \"client_secret_sign\": client_secret_sign,\n        \"type\": \"SELF\"\n    }\n\n    body = urllib.parse.urlencode(data_)\n    url = 'https://api.commerce.naver.com/external/v1/oauth2/token'\n    res = requests.post(url=url, headers=headers, data=body)\n    res_data = res.json()\n    if 'access_token' in res_data:\n        return res_data['access_token']\n    else:\n        raise ValueError(f'Token request failed: {res_data}')\n\n이 함수는 클라이언트 ID와 시크릿을 기반으로 네이버 API에서 access_token을 발급받습니다. bcrypt와 pybase64 라이브러리를 사용해 인증 서명을 생성하고, 이를 바탕으로 POST 요청을 보내 OAuth2 토큰을 받아온다.\n\n\n\n7.2.2 Q&A 데이터 가져 오기\nif params_bulletin == \"Q&A\":\n    current_datetime = datetime.datetime.now()\n    to_date = current_datetime.strftime('%Y-%m-%dT%H:%M:%S.100+09:00')\n    from_date = (current_datetime - datetime.timedelta(days=params_interval)).strftime('%Y-%m-%dT%H:%M:%S.100+09:00')\n\n    base_url = \"https://api.commerce.naver.com/external/v1/contents/qnas\"\n    query_params = {'page': 1, 'size': 100, 'fromDate': from_date, 'toDate': to_date}\n    headers = { 'Authorization': f\"Bearer {st_access_token}\" }\n    response = requests.get(base_url, params=query_params, headers=headers)\n\n사용자가 선택한 기간(params_interval)에 해당하는 Q&A 데이터를 네이버 API로부터 가져온다. 이 때 fromDate와 toDate를 포함한 URL 매개변수와 함께 GET 요청을 보낸다.\n\n\n\n7.2.3 응답 데이터 처리\narticles_data = []\nif response.status_code == 200:\n    data = response.json()\n    for qna in data['contents']:\n        createDate = qna['createDate']\n        question = qna['question']\n        answer = qna['answer'] if qna['answered'] == 1 else \"답변 필요\"\n        articles_data.append({'date': createDate, 'question': question, 'answer': answer})\nelse:\n    print(\"Error:\", response.text)\n\nAPI로부터 받은 JSON 데이터를 처리하여, 각각의 Q&A에 대해 질문과 답변을 추출한다. 답변이 없는 경우 “답변 필요”로 표시한다. 이를 DataFrame으로 변환하여 시각화할 수 있다.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>네이버 스마트스토어 API 연동</span>"
    ]
  }
]